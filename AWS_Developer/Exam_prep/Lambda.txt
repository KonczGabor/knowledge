Lambda:

	A cél a párhuzamos, izolált végrehajtás
	Each request to an AWS Lambda function triggers a separate "instance" or "execution context" of that function. 
	This means that multiple requests result in multiple concurrent executions. Each execution runs in isolation, with its own environment and resources. 
	This architecture allows Lambda to handle many requests in parallel without the executions interfering with each other.


	• FAAS: Function as a Service. U just have to deploy functions. Vrtual functions - no servers to manage.
	
	• Short Execution -uu to 15 minutes. 
	
	• Serverless executional environment(Containerized-Amazon linux, no reused guarantee ). Léteznek szerverek továbbra is, csak a felhasználó szemszögéből nézve nem neki kell manage-elni (provision).
	
	• Minden λ-nek lennie kell egy IAM-Role-nak és azoknak is akik hívni akarják direktbe.
		
	• Run code in Response to Events.
	
	• Egy λ-nak maximum 10GM RAM-ot dedikálhatunk.	
		Minél több a RAM-ot dedikálunk, autómatikusan a háttérben annált több CPU-t és Networkot dedikál magának.
	
	• Auto Scale. Egészen 10 GB RAM-ig dedikálhatunk erőforrást egy function-nek.
		Ha növejük a RAM-ot, akkor indirect a CPU és Network teljesítményt is húzzuk.
		128 MB-től egyesável(Mb-onként) egészen 10 GB-ig skálázhatunk egy λ-t.
			A háttérben arányosan a CPU-t is húzza magával, azt nem konfigurálhatjuk directbe.
			Minden elköltött 17
	
	• PRICING: 
		Paying for just the used computing-time (nem fizetünk ha nem fut a kód)
		Free tier of 1,000,000 AWS Lambda requests and 400,000 GBs of compute time
			‣ Fizetünk h mennyiszer lett meghívva
			‣ Fizetünk h mennyi ideig futott a function (milisec)
			
			
			
♦ Mire jó úgy általában?:
	• Készíthetünk egy REST API-t, ami meghívja a λ-inkat.			
	• Kinesis használhat λ-t data transformation-ra on the fly.
	• DynamoDB: ha elsül egy trigger, az meghívhat egy λ-t.
	• S3: gyakorlatilag bármi, pl ha létrejön a egy file.
	• CloudFront 
	• CloudWatch Evenets / EventBridge: Ha az infrastruktúránkban változás áll be. 
	• CloudWatch Logs 
	• SNS: to react Notifications
	• SQS: to process messages from SQS queues
	• Cognito: to react if some login to your database.
	• CRON Job
	
	Követlenül ALB is hívhatja, de akkor egy TargetGroupban kell lennie (Ez egy szinkron hívás, mert a user a HTTP/S végén várakozik).
		Ez úgy lehetséges h a HTTP request egy JSON-t ad át a λ-nak és a végeredmény JSON-t is az ALB visszalakítja HTTP-response-zá.
			return {"statusCode": 200, 
				"headers": {
					"Content-Type": "text/html"
				},
				"body": "<h1>Sajt!</h1>"
			}
		//Nyilván az ALB-nek rendelkeznie kell policy-val h meghívhassa a λ-t. 	
		
	
	
Easy Monitoring by CloudWatch.
	
	Logging
	
	By def saját VPC-ben jön létre, amit az AWS own-ol.
		Ezért nem is tudja elérni a saját erőroffásainkat a saját VPC-nkben
	
	Minden Lambda Functionnek rendelkeznie kell egy IAM Role-lal!
	
	Létre kell hozni egy Triggert, ami elsül valahonnan és bevezetni a paramétereket a Lambda-service be.
	
	1 Lambda function csak egy 1 VPC-hez csatlakozhat.
	
	Language support:
		Node.js (JavaScript)
		Java
		Go
		Python
		C#
		Ruby
		Custom Runtime API (Community supported: Rust)
	
	A container image-nek implementálnia kell a Lambda Runtime API-t.
		ECS/Fargate image-ek en futnak a λ-k.
		//Docker is not for AWS Lambda, it's for ECS/Fargate
		Egy container image max 10 GB méretű lehet.
	
	Részei:
		https://docs.aws.amazon.com/lambda/latest/dg/foundation-progmodel.html
			Handler
			Context 
			Logging /All stdout is logged
			Exceptions
	
			Példa:
				Handler method:
					exports.myHandler=function(event, context, callback)
					
					
Lambda:
	Serverless Compute
	Lifecycle:
		Develop -> Upload -> Monitor & troubleshoot
			Pieces of the programming model:
				Handler, Context, Logging, Exceptions
				
	Delete Lambda functions that u are no longer using		
	Bemenetként nem csak REST API, de SimpleQueueService is remek lehet
	A külső dependenciákat szervezzük be lokális változókba,
	Kerüljük a rekurzív kódot! -> Végtelen pénz égetés.		
	
Az összes Lambda exacution log letárolásra kerül az AWS CloudWatch Logs-ba.	

X-Ray is nagyon könnyen beköthető.
	A kódba be kell tenni az X-Rays SDK-t
		Managed policy AWSXRayDemonWriteAccess
	
	
	
	
	Integration with ALB:
		ALB-n vagy Gateway-en nyitunk egy HTTPS-endpointot
		A λ-k target group-okon belül kell éljenek.
		Ez egy szinkron metódus, mert meg kell várni a λ válaszát
		Az ALB-nek rendelkezni kell a policy-vel h meghívhassa a λ-t, de ez a háttérben beállítódik console-on.
		
		
		Hogyan alakítunk át egy HTTP requestet λ hívássá?			
			Minden beérkező HTTP request egy JSON-né fordul, amiből λ function paraméterei lesznek.
			Ugyanez fordítva is igaz, a λ visszatér egy JSON-nal, amibpl az ALB HTTP response-t állít elő.
			
			Itt jön be egy érdekes feature, a Multi-Header Values:
				Ugyanaz a query paraméter különböző értékekkel (?name=foo&name=bar) 
				egy array-é fordul: "queryStringParameters":{"name":["foo", "bar"]}
				A Target Group/Attribute-s ban lehet beállítani.
	
	
		Aszinkron kommunikácó esetén (a result nem jön vissza hozzánk, ez a lényeg, a cél, mert vagy sok van belőle[batch processing], vagy az adott API csak úgy hívható):
			Pl: SNS, S3, CW Events, CodePipeline (elindult, failelt, végzett)
			Az események egy EventQueue-ra kerülnel
				Ebből dolgoznak a λ -k.
					Ha a λ error-ral tér vissza, akkor vár 1 percet, 
					ha másodszorra is, akkor vár 2 percet,
					ha harmadjára is akkor beteszi egy DLQ (DeadLetterQueue) -ra  //Max 3 retry attempt létezik tehát.
						
			S3 bucket létrehozásánál van EventNotification block-ott lehet hivatkozni a λ-ra.
			//Ha negedélyezni akarjuk h egy λ SNS q-ba írjon, akkor meg kell kereseni a λ execution role-ját 
			és ahhoz csatolni kell egy SQS type policy-t.
	
		• Event Source Mappging (A λ-nak kell pullolnia a source-ról és válaszolni is fog, tehát szinkron):
			Kinesis Data Streams
			SQS @ SQS FIFO queu
			DyanmoDB Streams
		
			Two types:
				‣ Streams:
					Kinsesis and DynamoDB
						Egy iterátort bekonfigolhatunk h vagy a 
						- shard elejétől, 
						- egy time-stamptől
						- vagy az új elemtől
						induljon. 
					A processzelt itemek nem kerülnek le a steam-ről, így más consumerek is elérhetik.
					
						Batch size it nagyon nagy lehet
						
						Starting position:
							Elejétől
							Végétől
							TimeStamptől
							
						Concurrent batches per shard. Partion key szinten ki van eszközölve a read order.
				
				‣ Queues (van benne FIFO támogatás):
					Long Pollinggal pllolja az Event Source Mapping az SQS-t, hogy átadhassa egy λ-nak.
					Megadhatjuk a batch size-ot (1-10 //ez nem biztos) 
					Batch window: hány másodpercig gyűjtük a recordokat, mielött egy batch-be csomagoljuk őket.
					Lambda törli a messageet a queue-ról
					λ-nak addni kell policy-t h olvashasson a queue-ról (AWS LambdaSQSQueueExecutionRole)
	
			Ha nem használjuk Disable-re kell tenni, vagy törölni kell őket, mert golyamatosan pullolnak a source-ról.
				//Disable Trigger-on the Queue
	
	
 • Event Object és a Context Object egymást kiegészítik
	♦Event Object:
		JSON document ami az adatokat tartalmazza a λ function számára 
		A meghívó service-ről is tartalmaz adatot (EventBridge, SQS, SNS)
		Ezt a JSON-t az adott nyelv runtime-ja objec-té építi
			event.source
			event.region
	
	♦Context Object:
		Ez a memória objektum olyan függvényekkel bírm amik információt szolgáltatnak a a hívás, a hívott funkció és az environment részleteiről.
			context.crequestID
			context.functionName
			context.ARN
			context.MemoryLimit

♦ Destinations:
	Gyakorlatilag egy olyan DLQ function, ami nem csak a failelt, hanem a sikeres resultokat is gyűjtheti. Tud egyszerre üzemelni egy valós DQL-val.
		Common use-case h beállítunk egy SQS-t amire a Destination kiteszi a sikeres, másikra a sikertelen eventeket.
	

♦ λ Environment Variables:
	key-value parirs in string form 	
	A consolon direktbe felsorolhatjuk őket.
	
	
♦ Logging and monitoring:
	CW Logs-ba kerülnek letárolásra, ha be van állítva a policy h írhasson oda.
	CW Metrics-ben meg a Duration, Concurrent Execution, Invocations, Error counts, Success Rate, Throttles, Aysnc Delivery Failure, ... 
	
	
♦ Enable X-Ray:
	1, SDK in the code
	2, IAM Execution Role to write to X-RAY, ehhez kell ez a policy:
		AWSXRayDaemonWriteAccess	
	3, Env variables amik bekonfigolják az X-Ray-t:  //Ezek is lehetnek vizsgán
		_X_AMZN_TRACE_ID: contains the tracing header
		AWS_XRAY_CONTEXT_MISSING: by default, LOG_ERROR
		AWS_XRAY_DAEMON_ADDRESS: the X-Ray Daemon IP_ADDRESS:PORT
	
	
♦ Customization at the Edge:
	Edge function: "Előre tolt" kódok, amiket a CloudFront disztibúciókra telepíthetünk ki. Az a célja h csökkentsük a userek számára a latency-t.
		Pay for what we use
		Ezeket a function-öket Globally kell deployolni
		Serverless
		
		• Mire használjuk általában:
			- Website Security and Privacy
			- Dynamic Web Application at the Edge
			- Search Engine Optimization (SEO)
			- Intelligently Route Across Origins and Data Centers
			- Bot Mitigation at the Edge
			- Real-time Image Transformation
			- A/B Testing
			- User Authentication and Authorization
			- User Prioritization
			- User Tracking and Analytics
			
		• A Cloud Front "kettévágja" a tipikus requestet.
			
			Lépések: 
				1, Elindul a Clien-től a request, és a CloudFront már el is kapja. Ez eddig a "Viewer Request".
				2, A CloudFront továbbküldi az eredeti cél felé (szerverünk - origin): "Origin Request".
				3, Origin válaszol a CloudFront-nak: "Origin Response".
				4, CloudFront válaszol a Client-nek: "Viewer Response".
		
	Két fajtája van:
	
		• CloudFront Functions:
		
			‣ Lightweight functions written in JavaScript. Megváltoztatják a Viewer Requestet és a Viewer Response-t (Tehát az 1-es és 4-es phase-ben van szerepük).
			‣ High-scale, latency sensitive CDN customizations
			‣ Millions of request/second
			‣ Nem fér hozzá a Request Body-hoz
			‣ Nem fér hozz a hálózathoz, filerendszerhez
			‣ Max execution time < 1ms
			‣ Max memory 2 MB
				
				Célok:
					- Cache key normalization: A headerek, cookie-k, query stringek, URL-ek alapján létrehozni egy optimális Cache Key-t.
					- Header manipulation: Insert/Modify/Delete HTTP headers
					- URL rewrite/redirect
					- Request authentication/authorization
					- Create/validate JWT tokens => allow/deny requests
					
		• Lambda@Edge:
			‣ Az összes pházisban operálhatnak (1,2,3,4)
			‣ λ functions, amik NodeJS-ben, vagy Pythonban vannak írva.
			‣ Scales 1000s of requests/second
			‣ Egy Regioban kell megírni és a CF átviszi a többibe.	
			‣ Hozzá fér a Request Body-hoz
			‣ Hálózat, filerendszer hozzáférés
			‣ Max execution time 5-10 sec
			‣ Max memory 128 MB - 10 GB 
	
				Célok:
					Bármi
	
	
♦ Lambda by default:	
	Nem a mi VPC-nkben élnek, hanem az AWS, saját VPC-jében. Tehát nem tudnak hozzáférni a mi erőforrásainkhoz by default.
		Ő hozzáférhet bármilyen publikus weboldalhoz, API-hoz, DynamoDB-hez
	Ahhoz h a λ -nk hozzá tudjon férni az erőforrásainkhoz, meg kell adni h melyik VPC-nkben jöjjön létre (VPC-id), a Subnetet és SecurityGroup-ot
	 	A háttérben létre fog jönni egy ENI (Elastic Network Interface) a saját security group-jában
	 	A λ-nek rendelkeznie kell egy "AWSLambdaVPCAccessExecutionRole"-lal.
	 		Meg egy AWSLambdaENIManagementAccess policy-vel
	 	Meg kell bizonyosodni h mondjuk a saját RDS SG-nk beenged-e connection-t a λ SG-jéből.
	 	
	 Mi ennek a hátránya?
	 	Mivel a λ -nkat privát VPC-ben hoztuk létre, az most nem lát ki a public netre.
	 	Az EC2-vel ellentétben ha egy λ-t deployolunk public subnetre az nem fog kilátni és public IP-t sem kap.
	 		Szóval egy public SG-ben űlő NAT Gateway-t, vagy Nat Instance-ot kell használnunk, ami rámutat egy InternetGateWay-re.
	 			Ezzel igy DynamoDB-hez is hozzá tudunk férni.
	 				De DynamoDB-hez privát kapcsolattal IS hozzáférhatünk:
	 					Ilyenkor kell egy VPC Endpoint (VPC Endpoint GW)
	 	
	 	CloudWatch logok akkor is rögzítésre kerülnek, ha ezeket mind nem konfiguráltuk össze.
	 
	
	
Alias: Egy alias csak egy functionnek egy adott verziójára mutathat, más aliasokra nem. Egy verzióra mutathat több alias is.
	Ugyannanak a functiönnek különböző verziójára mutathatnak az aliasok. A legújabb lehet a dev, "alatta" a prod.
	A probléma, amit megoldanak, h nem kell direktbe egy esemény forrásból (S3) adott verzióra mutatni, elég az aliasra, a verzió úgyis elmászik.	
	
	
	
	
♦ Concurrency is the number of requests your function can handle at the same time. There are three types of concurrency controls available:

	Default (On-Demand) Execution: By default, AWS Lambda functions execute in an on-demand fashion where instances are dynamically created and scaled according to the incoming request rate. 
	This model provides maximum flexibility but includes variability in start-up latency due to cold starts.
	Provisioned Concurrency: Provides lower latency and more predictable performance by keeping a specific number of function instances always ready.
	Compute Savings Plans: Offers a way to reduce costs on predictable compute usage across multiple AWS services, including Lambda.

	Reserved concurrency (Compute Savings Plans)– guarantees the maximum number of concurrent instances for the function.
	When a function has reserved concurrency, no other function can use that concurrency. There is no charge for configuring reserved concurrency for a function.
	Reserved concurrency is ideal when you have critical applications that require immediate response times, and you cannot afford the latency that a cold start may introduce.
	It's also useful during predictable traffic spikes where you know you'll need increased capacity.
	

	Provisioned concurrency (preheated, ready to serve state)– initializes a requested number of execution environments so that they are prepared to respond immediately to your function's invocations. 
	Note that configuring provisioned concurrency incurs charges to your AWS account.
	Provisioned Concurrency is ideal when you have critical applications that require immediate response times, and you cannot afford the latency that a cold start may introduce. 
	It's also useful during predictable traffic spikes where you know you'll need increased capacity.		
	Gyakorlatilag azzonnal indítható példányok, amiért akkor is fizetünk, ha épp nem használjuk.
	
	

Ha egy RDB-hez akarunk csatlakozni akkor a λ-kat bele kell tenni egy privát VPC-be, saját subnettel. 
	Ezen belül minden λ egy elastic network interface-szel fog csatlakozni az RDH-hez. 
	

Function URL: ennek az a célja h teljesen közvetlenül, full direktbe HTTP-n keresztül meghívhassunk egy λ-t.
	Csak akkor lehet hozzárendelni egy λ-hot Function URL-t, ha még a λ nem lett kideployolva.	
	
	
Layer:	
	A λ function dependenciáit és külső library-jait külön layer-ekbe szervezzük, mert ezek soha, vagy csak nagyon ritkán változnak.	
	További előnye h más λ is hivatkozhat ezekre a "már kész" layerekre.
		Hivatkozhatunk 
			- official AWS layerekre
			- saját layerekre
			- bárki layerére ARN segítségel.
	
	
	A Lambda layer is a .zip file archive that can contain additional code or data. A layer can contain libraries, a custom runtime, data, or configuration files. 
	Layers promote code sharing and separation of responsibilities so that you can iterate faster on writing business logic. Layers do not increase the computational capacity of Lambda.
	
			
Filerendszerek λ -hoz:
	
	Lambdához filerendszert 			 
		EFS:
			Ez kicsit trükkös.
			Egy EFS egy VPC-hez kötött.
				Egy VPC-n belül több AZ van. 
					Egy AZ-ban több private/piblic subnet
						EFS Acces pointot kell létrehozni amin keresztül a λ már meghívható, viszont így az Acces point lesz a bottleneck
	
	
	
	 	
	
	
Lambda Authorizer (formerly: custom authorizer //valljuk be ez jobb volt, mert így legalább ki lehet találni h mit akar):
	Bearer token authentication strategy-t használ (OAUTH, SAML)
	Validáció után visszaad egy IAM Policy-t
	
	2 fajtája van:
		- Token based: JWT, OAuth
		- request parameter-based (header, query string paramteres, stageVariables, vagy $context) Csak ez támogatja a WebSocketet.
		
		
		
			
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
				
	
	
	
	
	
	
	
			
