S3:
	Simple Storage Service 
	
		Maga egy bucket végtelen méretü lehet és végtelen mennyiségű objektet tartalmazhat.
			Egy objekt mérete ami nem haladhatja meg az 5TB-ot.
			Ha 5 GB-nál nagyobb file-t szeretnénk feltölteni, azt "multi-part" uploaddal kell megtenni.
				Valójában már 100 megánál nagyobb fileok esetén is ajánlott.
				Ilyenkor az adott file több darabra lesz bontva és párhuzamosan lesz feltolva a szerverre, ahol az S3 újra összerakja.
				Ha nem stabil a kapcsolat, akkor is megér használni, mert nem kell elökről kezdeni a másolást.
			
		
		Egy bucket nem tartalmazhat más bucketeket, gyakorlatilag maga a koncepció az h flat legyen a struktúra.
			Hogy mímeljük a faszerkezetet a file(itteni definíció szerint object) nevekben szokás ezt feltüntetni: image/sajt.jpg
	
	
		Maga a szolgáltatás mindenhonnan elérhető, az adat 3 AZ-ban is le van tárolva, de a bucket Region-höz kötött, az alapján számlázódik.
		
		Fine-grained permissions /bucket lvl/object lvl
		
		
		Consistency of data:
			Read-after-wright consistency for new objects //9.1_3:40
		
		Lifecycle managmenet: gyakorlatilag CRON job h mit csináljon a fileokkal
		
		3 Class közül válaszhatunk a deklarálásnál:
			Standard
			Standard-Infrequent Acces:
				Akkor amikor ritkán kell, de akkor nagyon gyorsan..
			Zone-Infrequent Access:
				Ez csak egy AZ-ban van eltárolva, tehát kisebb a durability-je mint a többinek
			Reduced Redundancy Storage:
				Legacy
		
		
		Naming Convention:
			• No uppercase, No underscore
			• 3-63 characters long
			• Not an IP
			• Must start with lowercase letter or number
			• Must NOT start with the prefix xn--
			• Must NOT end with the suffix -s3alias
			
			
		Az S3 Object-re rámutat egy key. A key a bucketen belül a full realtive path az objeckttel együtt (maga az object név tehát nem).
			key = prefix + object name
			prefix = path to the object (elhagyható, ha a "rootban" van)
			s3://my-bucket/my_folder1/another_folder/my_file.txt
				bucket name: s3://my-bucket/
				prefix: my_folder1/another_folder/
				object name: my_file.txt
				key: my_folder1/another_folder/my_file.txt
				
		Objects can have:
			• Metadata (list of text key / value pairs – system or user metadata)
			• Tags (Unicode key / value pair – up to 10) – useful for security / lifecycle
			• Version ID (if versioning is enabled)
				
				
				
S3 Access Logs: A targetnek és a mentés helyének(S3 bucket) ugyanazon a Region-ban kell lenniük.
	Ha a target egy bucket és a mentés helye ugynazon bucket, akkor infinite loop alakul ki, jó nagy számlával.
	
	A targeten engedélyezzük és a célállomás policy-je is updatelve lesz h tudja fogadni a logokat.
	
	
S3 Access Point:
	Összetett S3 bucket policy-k, ruleok kiszervezése logikák alapján csomópontokba. Több Bucketet össze tudnak fogni.
	Ezkhez az AccessPointokhoz csatoljuk a policy-ket
	
	
	Bucket Policy:
		By
			IAM User
			Role
			Cross Account 
	
	
	
	
	Versioning
		Bucket lvl kell megadni
		Ami még nem volt verziókezelve mielőtt beállítottk a featuret, annak a version-je "null" lesz.
	
	
	
	
	Replication
		CRR: Cross Region Replication
		SRR: Same Region Replication
		
		Ha beállítjuk, akkor csak az újonnan létrehozott fileokról lesz replika.
		
		Replication change does not exist. So If I create a file, it will be replicated into a distant bucket, but if this bucket is under replication policy too, a sencod copy from taht obj will not appear into the third bucket.
	
	
	
	S3 Storage Classes

		• Amazon S3 Standard - General Purpose
			‣ Used for frequently accessed data
			‣ Low latency and high throughput
			‣ Sustain 2 concurrent facility failures
			‣ Use Cases: Big Data analytics, mobile & gaming applications, content distribution…
			
		• Amazon S3 Standard-Infrequent Access (IA)
			‣ For data that is less frequently accessed, but requires rapid access when needed
			‣ Lower cost than S3 Standard
			‣ Use cases: Disaster Recovery, backups
				
		• Amazon S3 One Zone-Infrequent Access
			‣ Use Cases: Storing secondary backup copies of on-premises data, or data you can recreate
		
			
		• Amazon S3 Glacier Instant Retrieval
			‣ Millisecond retrieval, great for data accessed once a quarter
			‣ Minimum storage duration of 90 days
		
		• Amazon S3 Glacier Flexible Retrieval
			‣ Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) – free
			‣ Minimum storage duration of 90 days
		
		• Amazon S3 Glacier Deep Archive
			‣ Standard (12 hours), Bulk (48 hours)
			‣ Minimum storage duration of 180 days
		
		• Amazon S3 Intelligent Tiering
		
		
		
	Obejct Encryption
		• Szerver oldalon:
			‣ Alapból az S3 Managed Key-e dolgozik
			‣ KMS CMK -val (Customer Managed Key)
			‣ Customer Provided Key -vel (a kulcsot át kell küldeni, amit csak HTTPS-sen lehet, és maga a kulcs nem tárolódik le.)
		
		• Kliens oldalon
				
		
	
	Encryption in flight (is also called SSL/TLS)
		Amazon S3 exposes two endpoints:
			• HTTP Endpoint – non encrypted
			• HTTPS Endpoint – encryption in flight
			
		Ha ki akarjuk erőltetni a HTTPS-t:
			Akkor létre kell hozni egy policy-t, ami DENY-ol Get Action-t az S3 Resource-on, Condition pedig SecureTransport: false
	
	
	CORS:
		Akkor is felléphet ha ugyanazon Account más bucketjei akarnak beszélni egymással, pl. Egy website statikus elemei nem férnek hozzá a másik bucket-hez, amiben a videó filkeok, képek vannak.
		To enable, we have to attach a XML configuration file into the bucket.
		
	
	
	
	
	Logging:
		Minden S3 interactiont lehet monitorozni, csak a végtelen loop elkerülése véget a logok mentési bucketje ne legyen monitorozás alatt.
	
	
	
	
	Pre-Signed URL-s: Ha valamilyen temporaly jogosultságokat akarunk adni:
		File feltöltési lehetőség ideiglenesen
		Hozzáférés prémium tartalmakhoz ideiglenesen:
			A signed URL (Uniform Resource Locator) is a URL that includes authentication information in its query parameters. 
			It is commonly used for providing temporary access to protected resources on the web, such as files stored in cloud storage services like Amazon S3 or Google Cloud Storage.	
		
		Hogyan?
			Az Owner legenerálja a pre-signed url-t és odaadja a usernek.
			//TBC
	
	Access Points:
		An Amazon S3 Access Point is a feature introduced by AWS to simplify managing data access at scale for applications using shared data sets on Amazon S3. 
		S3 Access Points are named network endpoints attached to buckets that you can use to perform S3 operations (such as PUT, GET, DELETE) on objects. 
		They offer a way to manage access that is tailored to specific applications, workloads, or users, making it easier to scale access to shared data sets across thousands of applications.

		Each access point enforces distinct permissions and network controls for any request made through it. 
		You can create access points with policies (Access Point Policy) that enforce specific access patterns and network controls without having to manage multiple bucket policies. 
		This feature is particularly useful for large-scale applications, where managing individual user permissions can become complex.

		Here are some key features and benefits of using S3 Access Points:

			‣ Fine-grained Access Control: Each S3 Access Point supports its own policy. 
			This allows for fine-grained access control that is tailored to individual applications or sets of users. 
			You can define specific access rights independent of the underlying bucket's policy.

			‣ Simplify Shared Data Set Management: For workloads and applications that share data sets in S3, 
			access points can simplify access management by providing a single point of control for a specific application, group of applications, or users.

			‣ VPC Integration: Access Points can be configured to allow access from a Virtual Private Cloud (VPC) to restrict access to resources within your private network, enhancing security.

			‣ Block Public Access: Like S3 buckets, Access Points can be configured to block public access, regardless of the bucket's settings, 
			helping to ensure that data isn't accidentally exposed to the internet.

			‣ Ease of Use: By using Access Points, you can reduce the complexity of your bucket policies and more easily manage access to shared data sets. 
			The ability to create distinct, fine-grained access policies for different applications or use cases helps in maintaining orderly and secure access patterns.

		To use S3 Access Points, you create an access point for your bucket, define the access policy for the access point, 
		and then provide the access point ARN (Amazon Resource Name) to the applications or users that need access to the S3 resources. 
		This approach decouples the management of access policies from the S3 buckets themselves, enabling more scalable and manageable access configurations.
	
		A VPC Endpoint is needed for to the Access point to be accessable from the internet 
	
	
Bucket Policy:	
	
Use bucket policies to manage cross-account control and audit the S3 object's permissions. 
If you apply a bucket policy at the bucket level, you can define who can access (Principal element), which objects they can access (Resource element), and how they can access (Action element). 
Applying a bucket policy at the bucket level allows you to define granular access to different objects inside the bucket by using multiple policies to control access. 
You can also review the bucket policy to see who can access objects in an S3 bucket.	
	
	
S3 Bucket Key: 
	An "S3 bucket key" specifically relates to a cost-saving feature 
	used in conjunction with Amazon S3's server-side encryption (SSE) with AWS Key Management Service (AWS KMS) known as the S3 Bucket Keys feature. 
	This feature reduces the costs of server-side encryption using AWS KMS by decreasing the request traffic from Amazon S3 to AWS KMS.	
	
		Purpose: The S3 bucket key reduces the need for AWS KMS to decrypt or encrypt each object individually within the bucket every time an S3 operation occurs. 
		Instead, it enables a bucket-level key that AWS KMS encrypts. This encrypted bucket key then encrypts data keys for individual objects.
		
		Performance and Cost: By reducing the number of calls made to AWS KMS, S3 bucket keys not only help improve performance but also lower the costs associated
		with the use of KMS keys for encryption operations.

		Security: The S3 bucket key itself is protected under your configured AWS KMS key and helps maintain robust security standards without compromising performance.
	
		How They Work Together in S3
			When you use Amazon S3 with server-side encryption enabled using AWS KMS (SSE-KMS) along with S3 bucket keys:

				- AWS KMS generates a unique data key for each object when it is written to S3.
				- This data key is then used to encrypt the data of the object.
				- The data key itself is encrypted (often referred to as the encrypted data key) using the S3 bucket key.
				- The S3 bucket key is an additional layer that uses the CMK from AWS KMS but reduces the number of direct interactions needed between S3 and KMS, 
				thus improving efficiency and reducing cost.

		Summary
			S3 Bucket Key: A feature to optimize the use of AWS KMS with S3 by reducing the number of necessary encryption and decryption calls for objects within a bucket, 
			thereby saving costs and potentially improving performance.
			
			Data Key: Part of the envelope encryption strategy used to encrypt the data itself, with the key being managed and protected by a master key (CMK).

	
	
	
Transfer Acceleration:
	Nagy mennyiségű adatot tudunk a hozzánk legközelebb lévő Edge Location-re feltölteni, és utána már az AWS saját hálózatán sokkal gyorsabban célba ér.
	Routing optimalizálással éri el.
	Hasznos on-premise adatok migrálására.	
	Csak engedélyezni kell a bucketen és kapunk egy új endpointot.
	
	
S3 Object Lock: 
	enables you to store objects using a "Write Once Read Many" (WORM) model. S3 Object Lock can help prevent accidental or inappropriate deletion of data.
	
	
S3 Analytics: By using Amazon S3 analytics Storage Class Analysis you can analyze storage access patterns to help you decide when to transition the right data to the right storage class. 
	You cannot use S3 Analytics to identify unintended access to your S3 resources.	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
